---
title: "Meetup 2 - Importing and Cleaning Data"
author: "Kampalr"
date: "February 24, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, error = FALSE, warning = FALSE)
```

For this meetup, we shall be importing and cleaning data obtained from data.ug. We shall be looking at the [PLE Results by district 2010 - 2016 dataset](http://catalog.data.ug/dataset/uneb-results/resource/6e5885bd-2952-4086-aaac-0c2aa58ec762).

We shall levearge on the use of ***base R functions*** as these functions tend to be the most popular for new entrants into R. For our next session, we shall introduce members to [tidyverse](https://www.tidyverse.org/) that provides a collection of functions purposely customised for data science tasks.

### Importing the data
The file that we are using is a standard CSV file containing details on PLE results for the period 2010 - 2016.

```{r dataImport}
url <- "http://catalog.data.ug/dataset/1242faeb-b5a0-4ffb-8274-9c9975aad183/resource/6e5885bd-2952-4086-aaac-0c2aa58ec762/download/ple-results-by-district-2010-2016.csv"

data <- read.csv(url, stringsAsFactors = FALSE)
head(data)
```

In the ideal case, we would have a document similar to a data dictionary that would help define what each column (variable) means and additional characteristics of these variables such as their expected types and value ranges. ***Unfortunately***, we were unable to find the corresponding document which may add some complexity when trying to understand the data without making a consultation with the data owner. 

## Cleaning the data
We won't attempt to completely clean the data set as this may take too much time but instead, we shall look at possible techniques to look at the data and invoke thinking on what approach could be taken to clean the dataset.

Let's first look at the spread of the data.

### 1. How many districts are there?

```{r districts}
districts <- readLines(file('districts.txt'))
districts

```

Looking at the [census data (2017)](http://www.ubos.org/onlinefiles/uploads/ubos/census_projections/District%20Single%20Years%20Final_17.07.2017.xls) from Uganda Bureau of Statistics, we can see that there are currently **```r length(districts)```** districts in Uganda.

What happens when we try to count the number of districts that are present in the PLE dataset?  
```{r districtCount}
districts_PLE <- as.data.frame(table(data$DISTRICT))
districts_PLE
```

We can observe that there are ***`r nrow(districts_PLE)`*** unique districts registered. By scrolling through the few rows, we notice a couple of things:

* There are duplicate districts (e.g. Abim, Adjumani, etc.). The districts have white spaces which prevent them from being recognised as the same.
* There are subcounties/municipalities listed as districts, e.g. Arua M/C, Arua Main, and Arua Mun.
 
Let's address the first issue and remove the white space and see whether our results will improve.
 
### Removing white space
 
```{r removeWhiteSpace}
data$DISTRICT <- unlist(lapply(X = data$DISTRICT, FUN = trimws))

# And let's test the new results
districts_PLE <- as.data.frame(table(data$DISTRICT))
districts_PLE

```

As we can see, the duplicate districts have been knocked out bringing the unique number of districts down to ***`r nrow(districts_PLE)`***. Brilliant.

We can now tackle the second observation.

### Standardise districts
We noted that there were a number of districts that were broken down into counties, subcounties and municipalities. As an example, we have Arua district:
```{r Arua} 
unique(data[grep(pattern = "*ARUA*", x = data$DISTRICT, ignore.case = TRUE), 'DISTRICT'])
```

This presents an interesting challenge. Using the official list of districts (the 'districts' object), we will need to identify those rows in the PLE dataset that have districts with a similar name. 

We can quickly do this by establishing a list of valid districts with the row numbers they correspond with in the PLE dataset: 

```{r findSimilarDistricts}
district_rows <- list()

for(district in districts) {
    rows <- grep(pattern = paste("*", district, "*", sep=""), x = data$DISTRICT)
    district_rows[[district]] <- rows
}
```

In such a situation, it would be better to enquire from the original data owner on how the data was collected so as to establish the best strategy to unifying similar datasets. 

In our circumstance, we shall add the corresponding variables for each similar area, for example, "ARUA", "ARUA M/C", "ARUA MUN." and "ARUA MAIN" would be combined to one record "ARUA".

But before we can execute our strategy, let's check the other variables to make sure they are sane.

### Do we have any null (NA) values?

Let's check to see whether there are any null (NA) values for each variable:
```{r nullChecks}
# Let's apply an NA check on each column
na_cols <- apply(data, 2, function(x) sum(is.na(x)))

# Let's print the result as a dataframe to ease the view.
na_df <- data.frame(Measure = names(na_cols), Value = na_cols, row.names = NULL)

# Let's order it in descending order
na_df <- na_df[order(-na_df$Value), ]

# Print out the summary
na_df
```

We observe that all observations have their "NUMBER.OF.SCHOOLS.UNEB.CENTRE" as blank (`r nrow(data)` observations). We cannot be sure whether this was a column added in error, whether this was an omission during the data import/export process or whether this was acutally not tallied. A further consult would be required with the data owner to find out why this is blank. However, for our example, we shall focus on maintaining these as ***NIL/ZERO***.

We also notice an interesting observation. We observed that there are ***`r na_df[na_df$Measure == 'FEMALE.TOTAL.DIV1', ]$Value`*** female students that did not achieve a DIVISION 1 during this period. Let's see in which districts this phenomenon occurred.

```{r femaleDiv1}
# Obtain a subset of the data containing total candidate and female candidate info
female_attendance <- data[is.na(data$FEMALE.TOTAL.DIV1), 
                          c('YEAR', 'DISTRICT', 'TOTAL.CANDIDATES', 'FEMALE.CANDIDATES')]

# Calculat the percentage of female candidates obtaining Division 1
female_attendance$FEMALE.ATTENDANCE.PERCENT <- 
  female_attendance$FEMALE.CANDIDATES / female_attendance$TOTAL.CANDIDATES * 100

# Print out the data 
female_attendance
```

We will notice that these are in remote areas with low female attendance to the exams compared to the total number of candidates. Take note that as discovered during our data cleaning process, no females obtained a Division 1 over this period. In the long run of things, this could form part of a recommendation for follow-up on education with the girl child.

Now, back to the data cleaning process...

For our benefit, we shall mark all the NA values with **NIL/ZERO**. The missing values, as they are small, will not cause any significant variation in the overall trend of the data:

```{r zerofyNA}
# Replace all NA values with NIL/ZERO
data[is.na(data)] <- 0
```

### What about merging similar districts?
Now that we have replaced the NA values with NIL/ZERO, we can merge the observations of similar districts into a single observation. We are assuming that:

* Values are independent and do not overlap in each district's consituency/municipality.
* Values will be grouped by year (and district) and associated values summed.

So, our approach will be:

* Group the observations by year
* For each year:
  + identify districts with similar names
  + sum up the values for the similar districts and rename the observations with the official district name
  + merge the new observations with the original dataset whilst dropping the older records.
* Merge the above year groups into a new dataset.

```{r cleanDataSet}
# Get the range of years
years <- unique(data$YEAR)

for(year in years) {
  sub_data <- subset(data, subset = data$YEAR == year)
#  unique(data[grep(pattern = "*ARUA*", x = data$DISTRICT, ignore.case = TRUE), 'DISTRICT'])
}

```